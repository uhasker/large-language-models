{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03009267-70b8-4092-b18b-3c5b646ebcd0",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16ac2bc5-051a-492d-be07-a402b73177c2",
   "metadata": {},
   "source": [
    "At its core, attention is a mechanism that allows a token vector to include information about the context of that token (i.e. the surrounding token vectors).\n",
    "\n",
    "As an example consider the token sequence $T_0, T_1, T_2$.\n",
    "It seems sensible that token $T_2$ should have some information about $T_0$ and $T_1$ if we want to model the sequence successfully.\n",
    "\n",
    "As usual, we will need a few imports from `torch`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed77978-938e-48cb-ac2d-51f9da359ec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7e85061a7790>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37203064-ab22-4e67-81f4-9dad94b4f898",
   "metadata": {},
   "source": [
    "## Linear Combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69830aee-ca82-418d-9599-dd084976e54b",
   "metadata": {},
   "source": [
    "We will continue working with our example sequence $T_0, T_1, T_2$.\n",
    "We will call the vectors that represent the tokens $\\mathbf{t_0}, \\mathbf{t_1}$ and $\\mathbf{t_2}$ respectively.\n",
    "\n",
    "Let's say that every token is represented by a vector of dimension $5$, i.e. the entire sequence is represented by a tensor of dimension $3\\times 5$.\n",
    "\n",
    "We will use a random tensor throughout this section, in reality this would be the result of the layer that precedes the attention layer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6da53e99-5f3c-4148-a688-1d82b517544d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3367,  0.1288,  0.2345,  0.2303, -1.1229],\n",
       "        [-0.1863,  2.2082, -0.6380,  0.4617,  0.2674],\n",
       "        [ 0.5349,  0.8094,  1.1103, -1.6898, -0.9890]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = torch.randn(3, 5)\n",
    "T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037751b8-d20d-486d-ae6b-aedd026ed286",
   "metadata": {},
   "source": [
    "Now let's say that we would like the token vectors to be able to \"look\" at each other.\n",
    "The simplest way would be to calculate linear combinations.\n",
    "\n",
    "For example, if we would like to get the information contained in $T_0$ and $T_1$, we might compute a linear combination of $\\mathbf{t_0}$ and $\\mathbf{t_1}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ece16362-aa68-4668-b43b-ef470b71371a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0752,  1.1685, -0.2018,  0.3460, -0.4278])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 2 * T[0] + 1 / 2 * T[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c1215d-db9f-40c4-8586-95f9d6a4b765",
   "metadata": {},
   "source": [
    "Similarly, if we would like to combine the information in $T_0, T_1$ and $T_2$ we might compute a linear combination of $\\mathbf{t_0}, \\mathbf{t_1}$ and $\\mathbf{t_2}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46383781-3447-4e3d-a141-da700babc7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2284,  1.0488,  0.2356, -0.3326, -0.6148])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 / 3 * T[0] + 1 / 3 * T[1] + 1 / 3 * T[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b0eedc5-51f1-45a9-8e90-80636adcdbb1",
   "metadata": {},
   "source": [
    "This doesn't look like a great idea, primarily because not every token is equally important for every token.\n",
    "Instead we want to have some kind of weights in our linear combinations which should be data-driven, i.e. we would like the linear combination to be:\n",
    "\n",
    "$w_0 \\cdot \\mathbf{t_0} + w_1 \\cdot \\mathbf{t_1} + w_2 \\cdot \\mathbf{t_2}$\n",
    "\n",
    "where the weights $w_0, w_1$ and $w_2$ should be data-driven parameters.\n",
    "\n",
    "That is, the input of a hypothetical attention layer would be a tensor containing the vectors $\\mathbf{t_0}, \\mathbf{t_1}$ and $\\mathbf{t_2}$, while the output would be another tensor containing new vectors of $\\mathbf{\\hat{t}_0}, \\mathbf{\\hat{t}_1}$ and $\\mathbf{\\hat{t}_2}$ that are certain linear combinations of the input vectors.\n",
    "\n",
    "Put differently, attention \"mixes\" the input vectors together and gives us new output vectors that were able to \"communicate\" with each other in some sense."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1494d019-fbf7-4799-b3e8-651ed244708a",
   "metadata": {},
   "source": [
    "## Naive Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0cc3f5a-b60c-46cb-9241-4afb125b23de",
   "metadata": {},
   "source": [
    "Let's take a stab at a very naive attention mechanism.\n",
    "The idea would be to calculate the similarity of every token with every other token.\n",
    "We could use the dot product for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd2cc6ad-22a6-441c-997c-e2f386f569b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention(0, 0) = 1.4987846612930298\n",
      "attention(0, 1) = -0.12174583971500397\n",
      "attention(0, 2) = 1.265914797782898\n",
      "attention(1, 0) = -0.12174582481384277\n",
      "attention(1, 1) = 5.602515697479248\n",
      "attention(1, 2) = -0.06531322002410889\n",
      "attention(2, 0) = 1.2659146785736084\n",
      "attention(2, 1) = -0.06531322002410889\n",
      "attention(2, 2) = 6.007389068603516\n"
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        dot_product = torch.dot(T[i], T[j])\n",
    "        print(f\"attention({i}, {j}) = {dot_product}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11b77401-c3e2-4dc1-8bb0-b9dba2692ac7",
   "metadata": {},
   "source": [
    "This can of course be done much more efficiently via matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b2bcb48-9d07-409b-a01c-3c0103536a3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4988, -0.1217,  1.2659],\n",
       "        [-0.1217,  5.6025, -0.0653],\n",
       "        [ 1.2659, -0.0653,  6.0074]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = torch.matmul(T, T.transpose(0, 1))\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb43c4ee-89d1-4a0a-a1b3-6e1f5f31eb21",
   "metadata": {},
   "source": [
    "Now we have a matrix of \"attention scores\" indicating how much attention vector $\\mathbf{t_i}$ should pay to vector $\\mathbf{t_j}$.\n",
    "We can now compute a linear combination using data-driven weights:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45c09161-5194-4e2a-86ba-7e060b78ccda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2045,  0.9488,  1.8346, -1.8501, -2.9674])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S[0, 0] * T[0] + S[0, 1] * T[1] + S[0, 2] * T[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a7643d-1eaf-4382-9881-560efc28a97b",
   "metadata": {},
   "source": [
    "Again we can realize this much more efficiently via matrix multiplication:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "72bcfddb-78cf-42da-a24d-5b5fee372464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2045,  0.9488,  1.8346, -1.8501, -2.9674],\n",
       "        [-1.1198, 12.3029, -3.6754,  2.6688,  1.6991],\n",
       "        [ 3.6518,  4.8810,  7.0084, -9.8898, -7.3800]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul(W, T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518d7940-b4b4-4774-af69-6998c10ce74a",
   "metadata": {},
   "source": [
    "Unfortunately this naive attention will not work well in practice.\n",
    "The reason is that we need to be able to differentiate between \"information that a token vector represents\" and \"information that a token vector is interested in\".\n",
    "\n",
    "For example, if a token vector encodes that it is the subject of a sentence it will currently pay high attention to other subjects of the sentence (mostly to itself).\n",
    "Instead, it should probably pay attention to e.g. token vectors that encode predicates of a sentence, articles etc.\n",
    "\n",
    "We note that this a hand-wavy intuition and token vectors represent mostly inscrutable high-dimensional concepts that often have no real analogy in linguistics.\n",
    "Despite this, the overall idea still works well in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e15c454-86d0-4157-afbb-f030ecf2cec9",
   "metadata": {},
   "source": [
    "## Key and Query Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f93a89e-7fce-47cc-9100-85a67147365e",
   "metadata": {},
   "source": [
    "We now introduce the first important component of the real self-attention mechanism - the **key vectors** and **query vectors**.\n",
    "\n",
    "Every token vector generates a key vector and a query vector.\n",
    "The key vector indicates the information that the token represents and the query vector contains the information the token is interested in.\n",
    "\n",
    "To continue our informal example, a token might have the key vector \"I am the subject of the sentence\" and the query vector \"I am interested in the predicate of the sentence\".\n",
    "\n",
    "The key vectors and query vectors are computed from the token vectors via simple linear layers.\n",
    "\n",
    "For our example, we will create random linear layers - in reality this would be parameters that our neural network would have to learn.\n",
    "Let's call the matrix that will produce the key vectors $W_K$ and the matrix that will produce the query vectors $W_Q$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3cecfd8-8ddc-4e88-918b-9bc4ef64fde3",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_K = torch.randn(5, 4)\n",
    "W_Q = torch.randn(5, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d95fb-5995-4d48-8f4e-036a947e5746",
   "metadata": {},
   "source": [
    "We can now compute the key vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327fea18-94c3-41f4-b52e-cc740a4023d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6023, -0.7260,  1.1799,  0.2383],\n",
       "        [-0.6521,  4.4224, -3.7460, -1.2657],\n",
       "        [-0.7106, -4.3429,  4.2984, -2.3664]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.matmul(T, W_K)\n",
    "K"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcca984a-554a-47ba-90c8-84d5f4b5043e",
   "metadata": {},
   "source": [
    "We can also compute the query vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8b5fd610-0068-4b92-ace4-ca11a9f3410b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.6964,  1.3355, -0.5133,  0.0674],\n",
       "        [ 1.6595, -0.4445, -0.1917,  1.7729],\n",
       "        [-0.1650, -2.9899, -3.8893,  1.2756]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q = torch.matmul(T, W_Q)\n",
    "Q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "823c0c54-6dd5-4d73-909d-b9cb2b943e03",
   "metadata": {},
   "source": [
    "Now we will compute the attention scores in a similar way as before.\n",
    "The big difference is that instead of computing the similarity of the token vectors with each other, we will _compute the similarity between the key vectors and the query vectors_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fa0e842-efc1-4ce9-a254-2b85f390c201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.5809,  8.8498, -6.9600],\n",
       "        [ 1.5185, -4.5739, -4.2686],\n",
       "        [-2.2135, -0.1601, -6.6347]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = torch.matmul(Q, K.transpose(0, 1))\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17cf4655-8803-405e-9b11-249ce9295e5b",
   "metadata": {},
   "source": [
    "A minor, but important technical detail is that we will need to scale the attention scores to avoid numerical instability:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "171f60c6-001b-4821-84c9-2fa289d8a001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2905,  4.4249, -3.4800],\n",
       "        [ 0.7593, -2.2869, -2.1343],\n",
       "        [-1.1067, -0.0801, -3.3173]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = S * (4**-0.5)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23cec72e-78f4-4664-8b87-1d6ebf523347",
   "metadata": {},
   "source": [
    "We still have one problem - right now our tokens can \"look into the future\".\n",
    "For example token $T_0$ can \"see\" $T_1$ and $T_2$.\n",
    "\n",
    "But during inference time, this will not be possible - we can't take into account tokens that haven't been generated yet.\n",
    "Therefore we should disable this during training as well.\n",
    "\n",
    "We will \"mask\" the attention scores of future tokens:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5dcf1a8b-91c9-4fe0-adf4-6e44a247bd19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2905,    -inf,    -inf],\n",
       "        [ 0.7593, -2.2869,    -inf],\n",
       "        [-1.1067, -0.0801, -3.3173]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimat = torch.tril(torch.ones(3, 3))\n",
    "S = S.masked_fill(trimat == 0, float(\"-inf\"))\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0b1c54-95b3-4e58-8820-71efd38f4a64",
   "metadata": {},
   "source": [
    "Finally, we will normalize the attention scores by computing the `softmax`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47b87fd2-d94a-4000-988c-c9d0ade501a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000],\n",
       "        [0.9546, 0.0454, 0.0000],\n",
       "        [0.2563, 0.7156, 0.0281]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S = F.softmax(S, dim=-1)\n",
    "S"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae4b5a4-f270-4388-bbfb-bb42c14e5764",
   "metadata": {},
   "source": [
    "## Value Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ca22c-8e0c-4292-ac17-3eb8bf2c19e7",
   "metadata": {},
   "source": [
    "Right now, we would apply the scores to the token vectors directly.\n",
    "\n",
    "It turns out that the attention mechanism performs even better if we introduce one more indirection and calculate **value vectors** from the token vectors and only then apply the scores.\n",
    "\n",
    "The computation of the value vectors works exactly like the computation of the key and query vectors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5b2da458-19a1-4044-bf6a-a1257ec0888d",
   "metadata": {},
   "outputs": [],
   "source": [
    "W_V = torch.randn(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cda1bd97-ec1d-427d-8d0a-ca7af37509e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9285,  0.3301,  1.8359, -1.3448],\n",
       "        [ 0.4676, -0.1512, -0.5678,  0.8648],\n",
       "        [ 0.6143,  2.6772, -1.3256, -3.2423]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "V = torch.matmul(T, W_V)\n",
    "V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98cec7b8-84ea-4033-ba46-28308c5ad7bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.9285,  0.3301,  1.8359, -1.3448],\n",
       "        [-0.8652,  0.3082,  1.7268, -1.2445],\n",
       "        [ 0.1138,  0.0517,  0.0270,  0.1831]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = torch.matmul(S, V)\n",
    "R"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
