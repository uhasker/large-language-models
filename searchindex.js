Search.setIndex({"alltitles": {"Activation Functions": [[3, "activation-functions"]], "Attention": [[5, null]], "Backpropagation in PyTorch": [[2, "backpropagation-in-pytorch"]], "Basic Layers": [[3, null]], "Building": [[0, "building"]], "Calculating the Logits": [[6, "calculating-the-logits"]], "Computational Graphs": [[2, "computational-graphs"]], "Computational Graphs and Backpropagation": [[2, null]], "Contribution": [[0, "contribution"]], "Deep Dive Into GPT-2": [[6, null]], "Dropout": [[3, "dropout"]], "Embeddings": [[6, "embeddings"]], "Executive Summary": [[1, "executive-summary"]], "Final Notes": [[4, "final-notes"]], "High-Level Overview": [[1, null]], "Implementing a SelfAttention Layer": [[5, "implementing-a-selfattention-layer"]], "It\u2019s Numbers All The Way Down": [[1, "its-numbers-all-the-way-down"]], "Key and Query Vectors": [[5, "key-and-query-vectors"]], "Large Language Models book": [[0, null]], "Layer Normalization": [[3, "layer-normalization"]], "Linear Combinations": [[5, "linear-combinations"]], "Loading the Model and Performing Inference": [[6, "loading-the-model-and-performing-inference"]], "Multi - Head Attention": [[5, "multi-head-attention"]], "Naive Attention": [[5, "naive-attention"]], "Optimizers": [[2, "optimizers"]], "Our First Neural Network": [[2, "our-first-neural-network"]], "Overfitting and Regularization": [[2, "overfitting-and-regularization"]], "Preface": [[7, null]], "Subword Tokenization": [[4, "subword-tokenization"]], "Tensor": [[2, "tensor"]], "The Architecture": [[6, "the-architecture"]], "The Attention Part": [[6, "the-attention-part"]], "The Backpropagation Algorithm": [[2, "the-backpropagation-algorithm"]], "The Batch Dimension": [[5, "the-batch-dimension"]], "The Byte-Pair Encoding Algorithm": [[4, "the-byte-pair-encoding-algorithm"]], "The Embedding Layer": [[3, "the-embedding-layer"]], "The First GPT2 Block": [[6, "the-first-gpt2-block"]], "The Four Components of a Large Language Model": [[1, "the-four-components-of-a-large-language-model"]], "The Idea": [[4, "the-idea"]], "The Linear Layer": [[3, "the-linear-layer"]], "The MLP Part": [[6, "the-mlp-part"]], "The Other GPT Blocks": [[6, "the-other-gpt-blocks"]], "The Parameter Update": [[2, "the-parameter-update"]], "Tokenization": [[4, null]], "Tokenizers in the transformers Library": [[4, "tokenizers-in-the-transformers-library"]], "Training a Large Language Model": [[1, "training-a-large-language-model"]], "Value Vectors": [[5, "value-vectors"]], "Vanishing and Exploding Gradients": [[2, "vanishing-and-exploding-gradients"]]}, "docnames": ["README", "chapter1/high_level_overview", "chapter2/computational_graphs", "chapter3/basic_layers", "chapter4/tokenization", "chapter5/attention", "chapter6/deep_dive_into_gpt_2", "preface"], "envversion": {"sphinx": 62, "sphinx.domains.c": 3, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 9, "sphinx.domains.index": 1, "sphinx.domains.javascript": 3, "sphinx.domains.math": 2, "sphinx.domains.python": 4, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinxcontrib.bibtex": 9}, "filenames": ["README.md", "chapter1/high_level_overview.md", "chapter2/computational_graphs.ipynb", "chapter3/basic_layers.ipynb", "chapter4/tokenization.ipynb", "chapter5/attention.ipynb", "chapter6/deep_dive_into_gpt_2.ipynb", "preface.md"], "indexentries": {}, "objects": {}, "objnames": {}, "objtypes": {}, "terms": {"": [0, 2, 3, 4, 5, 6], "0": [2, 3, 4, 5, 6], "00": 5, "000": 4, "0000": [3, 5], "0001": 2, "00013056159878900093": 2, "0002e": 6, "0005": 3, "0007": 5, "0019": 2, "0023": 5, "0032": 5, "0034": 5, "0037": 6, "0041": 5, "0065": 6, "0074": 5, "0086": 5, "01": [2, 3, 5], "0104": 6, "0108": 6, "0130": 3, "0142": 6, "0176": 6, "0177": 6, "0184": 6, "02": [5, 6], "0209": 6, "0236": 6, "0255": 6, "0257": 6, "0270": 5, "0274": 3, "0275": 6, "0278": 6, "0279": 5, "0281": 5, "03": [5, 6], "0308": 6, "0310": 5, "0315": 3, "0321": 6, "0326": 6, "0329": 5, "0336": 6, "0339": 5, "0349": 3, "0351": 5, "0358": 5, "0367e": 6, "0370": 6, "0382": 6, "0393": 6, "04": 6, "0420": 3, "0429": 6, "0437": 6, "0445": 6, "0448": 2, "04483687464928194": 2, "0454": 5, "0459": 2, "0469": 3, "0473": 2, "0473383390833865": 2, "0484": 6, "0485": 2, "0488": 5, "0497": 6, "05": [5, 6], "0503": [3, 5], "0504": 6, "0506e": 5, "0517": 5, "0530": 6, "0545": 2, "0546": 3, "0566": 3, "0589": 2, "0593": 5, "06": 6, "0620": 5, "0623": 5, "0653": 5, "0658": 5, "0674": 5, "0677": 3, "0697": 6, "07": 5, "0714": 6, "0752": 5, "0755": 6, "0762": 6, "0780": 6, "0782": 3, "08": 6, "0801": 5, "0815": 3, "0828": 6, "0830": 5, "0832": 6, "0853": 3, "0857e": 5, "0888": 6, "09": 6, "0902": 3, "0964": 6, "0987": 5, "0994": 5, "0x7f0f39eae310": 2, "0x7f695a277b80": 3, "0x7f695a28b280": 3, "0x7f695c394c40": 3, "0x7f6a0baa15b0": 3, "0x7fb201b470b0": 5, "1": [1, 2, 3, 4, 5, 6], "10": [2, 3, 4, 5, 6], "100": [2, 4, 6], "101": 4, "1010": 6, "102": [4, 6], "1020": 6, "1024": 6, "103": [4, 6], "1035": 6, "104": [4, 6], "105": [4, 6], "1051": 3, "1057": 6, "106": 6, "1067": 5, "107": [4, 6], "108": [4, 6], "1081": 3, "1085": 6, "109": 4, "11": [2, 5, 6], "110": [4, 6], "1103": 5, "111": [4, 6], "1115": 5, "113": 6, "114": 4, "115": [4, 6], "116": [4, 6], "1163": 5, "117": 4, "1174": 5, "1179": 5, "119": 4, "12": [2, 5, 6], "120": 4, "1206": 5, "1212": [4, 6], "1217": [3, 5], "1219": 3, "122": 4, "1228": 3, "1229": 5, "123": 1, "1232": 6, "1246": 5, "126": 4, "1275": 3, "1288": [3, 5], "13": [2, 6], "1304": 6, "1335": 6, "1343": 5, "1356e": 5, "14": 2, "1406": 6, "1453": 3, "1465": 3, "1468": 6, "1472": 3, "1487": 6, "15": [2, 6], "1510": 6, "1512": 5, "1568": 5, "1586": 5, "16": 2, "1601": [4, 5], "1614": 5, "1638": 6, "1650": 5, "1666": 6, "1672": 6, "1685": 5, "1754": 6, "1799": 5, "18": 2, "1822": 5, "1831": 5, "1849": 5, "1853": 6, "1863": 5, "1870": 6, "1882": 5, "19": [4, 6], "1910": 6, "1911": 6, "1917": 5, "1932": 5, "1967": 5, "1973": 3, "1981": 3, "1987": 6, "1e": [3, 6], "1x5": 6, "1x5x768": 6, "2": [1, 2, 3, 4, 5, 7], "20": [1, 5], "2018": 5, "2019": 6, "2025": 6, "2028": 6, "2041": 5, "2046": [3, 6], "2048": 6, "2064": 3, "2070": 6, "2080": 5, "2082": 5, "2083": 6, "2090": 5, "21": [4, 5, 6], "2104": 5, "2135": 5, "2142": 5, "2173": 5, "2181": 3, "22": 5, "2260": 5, "2284": 5, "23": 2, "2303": 5, "2304": 6, "2311": 3, "2325": 5, "2326": 6, "2341": 3, "2345": [3, 5], "2347": 3, "2350": 3, "2356": 5, "2364": 5, "2383": 5, "2396": 5, "2423": 5, "2439": 5, "2445": 5, "2456": 6, "2464": 6, "2477": 6, "2478": 5, "2480e": 5, "24k": 1, "25": 6, "2511": 6, "2539": 6, "2553": 5, "256": 4, "2563": 5, "257": 4, "2576": 3, "258": 4, "2585": 5, "259": 4, "260": 4, "261": 4, "262": 4, "2625": 5, "2627": 6, "2628": 6, "263": 4, "264": 4, "265": 4, "2657": 5, "2659": 5, "266": 4, "2660": 3, "267": 4, "2674": 5, "268": 4, "2686": 5, "269": 4, "2695": [3, 5], "27": 5, "270": 4, "271": 4, "272": 4, "2725": 5, "273": 4, "274": 4, "2742": 3, "2743": 5, "275": 4, "2756": 5, "276": 4, "2766": 6, "277": 4, "278": 4, "2780": 3, "2784": 3, "279": 4, "2793": 5, "280": 4, "281": [4, 6], "2814": 6, "282": 4, "283": 4, "284": 4, "285": 4, "2850": 5, "286": [4, 6], "2869": 5, "287": [4, 6], "288": 4, "289": 4, "290": [4, 6], "2905": 5, "291": 4, "292": 4, "293": 4, "2930": 6, "294": 4, "295": 4, "2956": 5, "296": 4, "2967": 6, "297": 4, "298": 4, "2984": 5, "2987": 3, "299": 4, "3": [2, 3, 4, 5, 6], "30": 1, "300": 4, "301": 4, "302": 4, "303": 4, "304": 4, "3049": 5, "305": 4, "3057": 3, "3074": 5, "3082": 5, "3085": 6, "3151": 5, "3173": 5, "318": [4, 6], "31884": 4, "3189": 3, "3195": 6, "3198": 5, "32": 4, "3211": 3, "3218": 5, "3220": 3, "3231": 6, "3242": 3, "3256": 5, "326": 6, "3292": 6, "33": 4, "3301": 5, "3317": 6, "3326": 5, "3343": 5, "3355": 5, "3367": [3, 5], "3374": 3, "3414e": 6, "3429": 5, "3447": 5, "3448": 5, "3449": 5, "3460": 5, "3466": 3, "3488": 5, "35": 6, "351": 6, "3519": 3, "3584": 5, "3598": 3, "36": 6, "3611e": 5, "3636": 5, "3650e": 5, "3664": 5, "3685": 6, "3712": 6, "3740": 3, "3750": 5, "3775406687981454": 2, "38": 2, "3826": 5, "3830": 3, "39": 6, "3900": 5, "3942": 5, "3970": 3, "3981": 5, "4": [1, 2, 3, 4, 5, 6], "4036": 6, "4041": 3, "4083": 5, "41": 6, "4112": 6, "4115": 3, "4181": 3, "42": [3, 5, 6], "422": 6, "4224": 5, "4236": 3, "4241": 5, "4245": 3, "4249": 5, "4263": 3, "4266": 3, "4278": 5, "4315": 5, "4377": 6, "4391": 5, "44": [4, 6], "4440": 5, "4445": 5, "4451": 3, "4496": 3, "45": 4, "4504": 5, "4506": 5, "4535": 5, "4544": 3, "46": 4, "4607": 3, "4617": 5, "4645": 6, "4650": 5, "4657": 5, "4670": 3, "4673": 6, "4687": 3, "4689": 3, "4703e": 6, "4704": 5, "47407698418010663": 2, "4792": 5, "4800": 5, "4802": 5, "4814": 6, "4868": 6, "4879": 3, "4938": 6, "4964": 5, "4988": 5, "4989": 5, "4993": 5, "4x3": 3, "5": [2, 3, 4, 5, 6], "50": 4, "5000": [2, 3], "5013": 5, "5018": 3, "5025": 5, "50257": [4, 6], "5067": 5, "5089": 6, "5090": 3, "5111": 5, "5116": 3, "5126": 5, "5133": 5, "5185": 5, "5188": 5, "5191": 3, "5214": 5, "5232": 3, "5315": 5, "5341": 5, "5349": 5, "5390": 6, "543": 6, "5565": 3, "5600": 5, "5601": 3, "5678": 5, "5694": 6, "5701": 6, "5736": 3, "5739": 5, "5750": 3, "5796": 6, "5809": 5, "5815": 3, "5855": 5, "5952": 3, "5979": 5, "6": [2, 4, 5], "6023": 5, "6025": 5, "6064": 5, "6148": 5, "6158": 6, "6174": 5, "6192": 5, "6198": 5, "62": 2, "6225": 2, "6292": 5, "6344": 3, "6347": 5, "6380": 5, "6397": 5, "64": 6, "6416": 6, "6417": 3, "6488": 3, "6521": 5, "6537": 5, "6559": 5, "6595": 5, "6627": 6, "6645": 3, "6679": 5, "6683": 5, "6708": 3, "6772": 5, "6827": [4, 6], "6898": 5, "6921": 3, "6931": 2, "6931471805599453": 2, "6964": 5, "6971": 5, "6989": 6, "7": [2, 5], "70": 2, "7039": 6, "7066": 5, "7068": 6, "7090": 5, "7092": 6, "71": 6, "7106": 5, "7156": 5, "72": 6, "7237": 3, "7244": 6, "7260": 5, "7268": 5, "7291": 6, "73": 6, "7343": 3, "7357": 3, "7421": 3, "7444": 6, "7460": 5, "7488": 5, "7504": 3, "7508": 3, "7539": 6, "7593": 5, "7596": 3, "76": 6, "7636": 5, "768": 6, "7729": 5, "7746": 3, "7753": 5, "7858": 5, "7860": 6, "7868": [5, 6], "7916": 3, "7947": 5, "7977": 3, "8": [2, 4, 5], "8033": 5, "8057": 5, "8067": 5, "8094": 5, "81": 6, "8131": 6, "8140": 3, "8172": 3, "8196": 6, "82": 6, "8218e": 6, "8263": 2, "8359": 5, "8368": 5, "84": 4, "8437": 6, "8455": 3, "8476": 3, "8498": 5, "8508e": 5, "8515": 6, "8532": 5, "8630": 5, "8648": 5, "8654": 6, "88": 2, "8819e": 6, "8827": 2, "8847": 2, "8880": 5, "8889": 6, "8893": 5, "8963": 3, "9": [2, 4, 5, 6], "9190": 6, "9267": 5, "9281": 6, "9314": 5, "9370": 6, "94": 2, "9408": 5, "9416": 2, "9435": 2, "9444": 3, "9469867809360202": 2, "9470": 2, "9470e": 5, "9546": 5, "9554": 3, "9585": 5, "9600": 5, "9637": 5, "9648": 3, "9676": 5, "9680": 6, "97": 4, "9727": 5, "9770": 3, "9781": 5, "9803": 6, "9851": 5, "9873": 5, "9890": 5, "9891": 5, "9892": 5, "9899": 5, "99": [4, 6], "9933": 5, "9959": 5, "9977": 3, "9999e": 5, "A": [1, 2, 3, 4, 5], "AND": 2, "And": [1, 2, 3, 5, 6], "As": [1, 2, 3, 5, 6], "At": [1, 4, 5, 6], "But": [1, 2, 3, 5], "By": 2, "For": [1, 2, 3, 4, 5, 6], "If": [2, 3, 4, 6], "In": [1, 2, 3, 4, 5, 6], "Into": 7, "It": [2, 3, 4, 5], "Not": 3, "Of": 2, "One": [1, 3, 4], "That": [2, 3, 5], "Then": [1, 2, 3, 5], "There": [2, 4, 5, 6], "These": [1, 2, 4, 5, 6], "To": [1, 2, 3, 4, 5, 6], "With": [3, 6], "_": 5, "__init__": [2, 3, 5], "__version__": 6, "_b": 5, "_build": 0, "_c": [3, 5], "_split_head": 6, "abl": [2, 4, 5, 6], "about": [1, 2, 3, 5, 6], "abov": [2, 3], "accid": 2, "accomplish": [2, 3, 5, 6], "account": 5, "achiev": 2, "across": [3, 6], "act": 6, "act_output": 6, "activ": 6, "actual": [1, 2, 3, 4, 5, 6], "ad": 2, "add": [2, 6], "addbackward": 2, "addbackward0": [3, 6], "addit": [1, 2, 3, 5], "addition": [2, 4, 5], "addmmbackward0": 3, "address": [3, 6], "adequ": 1, "adjust": 1, "af": 4, "affin": 2, "aforement": 5, "after": [1, 2, 6], "again": [1, 2, 3, 5, 6], "algebra": 3, "all": [2, 3, 4, 5, 6], "allow": [1, 2, 3, 4, 5], "allowed_speci": 4, "along": [2, 3, 6], "alpha": 2, "alreadi": [2, 3, 5, 6], "alredi": 6, "also": [1, 2, 3, 4, 5, 6], "altern": 4, "although": 1, "alwai": [1, 3, 5], "am": 5, "among": 6, "an": [1, 2, 3, 4, 5, 6], "analog": 5, "analogi": 5, "ani": [1, 2, 3, 4], "annoi": 2, "announc": 1, "anoth": [2, 3, 5, 6], "answer": 1, "antroph": 1, "anywher": 1, "apart": [1, 2, 3], "apostroph": 4, "appear": 1, "append": 4, "appl": 1, "appli": [1, 2, 3, 5, 6], "approach": [2, 4], "appropri": 2, "approxim": [2, 3], "ar": [1, 2, 3, 4, 5, 6], "arang": [2, 3], "arbitrari": [1, 2, 5], "area": 2, "aren": [2, 4], "argmax": 6, "argument": 3, "arm": [1, 2], "around": 2, "arrai": 2, "arriv": [1, 2], "art": 2, "articl": [1, 5], "asdasdaf": 4, "ask": 1, "assign": 2, "associ": [2, 5], "assum": 2, "attempt": 2, "attent": [1, 4, 7], "attention_input": 6, "attention_mask": [4, 6], "attention_output": 6, "attention_residu": 6, "attn": 6, "attn_dropout": 6, "attn_head_s": 6, "attn_mask": 6, "attribut": 6, "author": 2, "auto": [4, 6], "autograd": 2, "automat": [0, 2, 6], "automobil": 1, "automodelforcausallm": 6, "autonotebook": [4, 6], "autosimplenet": 2, "autotoken": [4, 6], "averag": 5, "avg": 5, "avoid": [3, 5], "awar": 2, "b": [2, 3, 4], "back": [2, 3, 4, 5, 6], "background": 2, "backpropag": [3, 7], "backward": [2, 6], "backward_sorted_nod": 2, "bad": [2, 3], "ball": 1, "banana": 1, "bar": 6, "base": [2, 6], "basic": [1, 2, 4, 5, 6, 7], "bat": [1, 5], "batch": [1, 3, 6], "batch_dim": 3, "batch_siz": 5, "bce": 2, "bceloss": 2, "bcelossbackward": 2, "becaus": [1, 2, 3, 5], "becom": [1, 2, 3, 4], "been": [1, 3, 5], "befor": [0, 2, 3, 4, 5, 6], "begin": [2, 4, 6], "behavior": 4, "behind": [1, 2], "benef": 5, "benefit": [2, 5], "bernoulli": 3, "better": [2, 4, 5], "between": [1, 2, 3, 4, 5], "beyond": [3, 4], "bia": [2, 3, 5, 6], "big": [2, 5], "biggest": 3, "billion": [1, 6], "binari": 2, "binarycrossentropybackward0": 2, "bit": [2, 4], "blow": 5, "bmatrix": 2, "book": [1, 3, 4, 6], "bore": [1, 5, 6], "borrow": [2, 5], "both": [1, 2, 4, 5, 6], "box": 2, "bpe": 4, "branch": 2, "break": [2, 3, 4], "briefli": 3, "broader": 2, "bug": 3, "build": [3, 4], "builtin": [2, 3], "bunch": 2, "c": [2, 3], "c_attn": 6, "c_fc": 6, "c_fc_output": 6, "c_len": 5, "c_proj": 6, "c_proj_output": 6, "calc_output_valu": 2, "calcul": [2, 3, 5], "call": [1, 2, 3, 4, 5, 6], "can": [1, 2, 3, 4, 5, 6], "capabl": [3, 5], "captur": 6, "car": 1, "care": [1, 2, 5, 6], "carefulli": 2, "carri": 2, "case": [1, 2, 3, 4, 6], "cat": [1, 5], "causallmoutputwithcrossattent": 6, "cave": [1, 5], "cdot": [2, 5], "certain": [2, 4, 5], "certainli": 4, "chain": 2, "challeng": [2, 3], "chanc": 1, "chang": [2, 5, 6], "chapter": [1, 2, 3, 4, 6], "charact": 4, "chat": 1, "chatgpt": 1, "check": [2, 3, 4, 6], "choos": 6, "chose": 6, "chr": 4, "clash": 2, "class": [2, 3, 4, 5, 6], "classif": 2, "clean_up_tokenization_spac": 4, "clear": 3, "clearli": 5, "clone": 0, "close": [1, 2, 3, 6], "closer": [2, 5], "cloud": 6, "cluster": 1, "code": [2, 3, 6], "codebas": 6, "collect": 1, "com": 4, "combin": [1, 2, 6], "come": [2, 5], "commit": 0, "common": [2, 3, 4, 5], "commonli": [2, 3], "commun": 5, "compani": 1, "compar": [3, 6], "complet": [1, 2], "complex": [2, 3], "complic": [1, 2, 3, 5, 6], "compon": [2, 5, 6], "componentwis": 2, "composit": 3, "comput": [1, 3, 5, 6, 7], "computation": 5, "compute_loss": 2, "concept": [1, 2, 3, 5], "conceptu": [1, 4, 5], "concern": 2, "concret": 1, "confid": 2, "confirm": 2, "confus": 2, "connect": 6, "consequ": 2, "consid": [1, 2, 3, 4, 5, 6], "consider": 2, "consist": [1, 2, 6], "consol": 3, "constant": 2, "constraint": 2, "construct": [2, 3, 6], "contain": [1, 2, 3, 5, 6], "content": [5, 7], "context": [1, 5], "contextu": 1, "contigu": [5, 6], "continu": [1, 3, 4, 5], "contribut": 2, "control": 2, "conv1d": 6, "convent": 6, "convert": [1, 2, 4], "convert_ids_to_token": 4, "convolut": 2, "core": [1, 4, 5], "corpu": 1, "correct": [2, 3, 5, 6], "correctli": 2, "correspond": [4, 5, 6], "could": [1, 2, 3, 4, 5, 6], "count": [4, 6], "cours": [1, 2, 5], "cover": 4, "creat": [1, 2, 3, 4, 5], "crossentropi": 2, "crucial": 3, "ctx": 2, "cu121": 6, "cumul": 3, "current": [2, 5, 6], "cut": 3, "d": [2, 3, 4, 5], "d_": 5, "d_in": [3, 5], "d_out": [3, 5], "dai": 5, "danger": 6, "data": [1, 2, 5], "databas": 5, "dataset": [1, 2], "deal": [2, 5], "declar": 2, "decod": [4, 6], "decompos": 2, "decreas": 2, "dedic": 2, "deep": [2, 3, 7], "def": [2, 3, 4, 5, 6], "default": [3, 4], "defin": [2, 3, 4, 5], "definit": 2, "degre": 1, "denot": 2, "dens": 3, "depend": [0, 2, 3], "depract": 4, "deriv": [2, 3, 6], "descent": [2, 6], "describ": 3, "descript": 2, "despair": 2, "despit": 5, "detail": [1, 4, 5, 6], "determin": 5, "develop": 2, "dictionari": 4, "did": [2, 6], "differ": [1, 2, 3, 4, 5, 6], "differenti": [2, 5], "dim": [2, 3, 5, 6], "dimens": [1, 2, 3, 6], "dimension": [1, 2, 3, 5, 6], "direct": 2, "directli": [2, 3, 4, 5, 6], "directori": 0, "disabl": [3, 5, 6], "discard": 4, "discret": 3, "discuss": [1, 2, 3, 6], "distinct": [2, 4], "distribut": [1, 3, 6], "dive": [1, 5, 7], "dldb": 2, "dldw1": 2, "dldw2": 2, "dldy": 2, "do": [1, 2, 3, 4, 5, 6], "document": 1, "doe": [2, 3, 6], "doesn": [2, 4, 5], "dog": 1, "dollar": 1, "don": [1, 2, 4, 5], "done": [1, 2, 5], "dot": [2, 5], "dot_product": 5, "doubl": 6, "down": [2, 4], "draw": 2, "drawback": 3, "drive": 2, "driven": 5, "drop": [3, 6], "drop_i": 3, "drop_x": 3, "dropout": [5, 6], "dropout_lay": 3, "dropout_p": 6, "dtype": 6, "dure": [2, 3, 5], "dydz": 2, "e": [1, 2, 3, 4, 5, 6], "each": [1, 2, 3, 4, 5, 6], "earlier": 2, "easi": [2, 6], "easili": [2, 3], "edg": 2, "effect": 2, "effici": [2, 5], "either": [1, 2], "element": [2, 3, 5], "elementwis": [2, 3], "elementwise_affin": 6, "els": [2, 4], "emb_dim": 3, "emb_i": 3, "emb_x": 3, "embarrassingli": 1, "embed": 1, "embedding_dim": 3, "embedding_lay": 3, "embeddingbackward0": 3, "emphas": [3, 5], "en": [4, 6], "encapsul": 3, "encod": 5, "encoded_id": 4, "encoded_input": [4, 6], "encount": 3, "encourag": 6, "end": [1, 2, 4, 5], "endoftext": 4, "english": [1, 4], "enough": 2, "ensur": 3, "entir": [5, 6], "entri": 5, "environ": 6, "eo": 1, "ep": [3, 6], "epoch": 2, "equal": [4, 5], "error": [3, 4], "especi": [4, 6], "essenti": [2, 4, 6], "etc": [1, 5], "etween": 5, "eval": 3, "evalu": 3, "even": [1, 2, 3, 4, 5, 6], "ever": [1, 2], "everi": [1, 2, 3, 4, 5, 6], "everyth": [2, 4], "everywher": 3, "exactli": [4, 5], "examin": 2, "exampl": [1, 2, 3, 4, 5, 6], "except": [4, 6], "exception": 2, "excess": 2, "execut": [0, 2, 3], "exercis": [2, 3], "exist": 4, "exit": 5, "exp": [2, 3], "expect": [3, 4, 5], "expens": [0, 5], "explain": [1, 3], "explan": 3, "explicitli": 2, "express": 2, "extract": 6, "extrem": [2, 3, 4, 6], "f": [2, 3, 4, 5, 6], "fact": [2, 3, 5, 6], "factor": [3, 5], "fals": [3, 4, 5, 6], "familiar": [2, 6], "fanci": [2, 3], "fanciest": 2, "far": [1, 2, 3, 4, 5, 6], "fashion": 2, "featur": [3, 5], "fed": [1, 5], "feed": 1, "feel": [1, 2], "few": [2, 3, 5, 6], "field": [1, 3], "figur": 4, "file": 6, "final": [1, 2, 3, 5, 6], "find": 6, "fine": [2, 3], "finetun": 1, "first": [1, 3, 4, 5], "fit": [1, 2], "five": 6, "flaw": 4, "flew": [1, 5], "fli": 1, "float": [2, 4, 5], "flow": [2, 6], "fngrl": 1, "follow": [1, 2, 3, 4, 5, 6], "forc": 3, "forget": 3, "form": [2, 4, 6], "formal": [1, 2], "format": 4, "formula": [2, 3], "forward": [2, 3, 5, 6], "forward_r": 2, "forward_sorted_nod": 2, "found": [4, 6], "four": 2, "fourth": 1, "frac": [2, 3, 6], "frequenc": 4, "frequent": 4, "from": [0, 1, 2, 3, 4, 5, 6], "from_pretrain": [4, 6], "front": 5, "fruit": 1, "full": 3, "function": [1, 2, 4, 5, 6], "fundament": [1, 2], "further": [1, 3, 4], "furthermor": 3, "futur": 5, "futurewarn": 4, "g": [2, 5], "gain": 2, "garbag": 4, "gaussian": 3, "gelu": 3, "gelu_i": 3, "gelu_x": 3, "gener": [0, 1, 2, 3, 4, 5, 6], "get": [1, 2, 4, 5, 6], "get_encod": 4, "get_input_valu": 2, "get_local_grad": 2, "get_most_common_token_pair": 4, "get_output_nod": 2, "get_token_pair_count": 4, "giant": 1, "github": 4, "give": [1, 2, 5, 6], "given": [1, 2, 3], "glimps": 4, "gloss": 1, "go": [2, 3, 5], "good": [1, 2, 3, 5], "got": 2, "gpt": [1, 7], "gpt2": 4, "gpt2block": 6, "gpt2lmheadmodel": 6, "gpt2mlp": 6, "gpt2model": 6, "gpt2sdpaattent": 6, "gpt2tokenizerfast": [4, 6], "gpu": [1, 6], "grad": 2, "grad_fn": [2, 3, 5, 6], "grad_loc": 2, "grad_output": 2, "gradient": 6, "graph": [3, 6, 7], "graphic": 6, "grasp": [2, 3], "great": [2, 5], "greatli": 3, "ground": 4, "group": 3, "grow": 4, "guess": [1, 5], "h": [2, 3, 6], "h1": 2, "h2": 2, "h_1": 2, "h_2": 2, "ha": [1, 2, 3, 4, 5, 6], "had": 2, "hadamard": 2, "half": 3, "hand": [2, 5], "handl": 4, "happen": 4, "hard": [3, 4], "harder": 4, "hasn": 3, "have": [1, 2, 3, 4, 5, 6], "haven": 5, "he": 1, "head": 6, "head_dim": [5, 6], "head_kei": 6, "head_out": 5, "head_out_combin": 5, "head_queri": 6, "head_valu": 6, "hello": 4, "help": [3, 4, 6], "helper": [4, 6], "here": [1, 2, 3, 4, 5, 6], "hf_hub_disable_progress_bar": 6, "hi": 1, "hidden": 6, "hidden_s": 6, "hidden_st": 6, "high": [2, 3, 5, 7], "higher": [1, 2, 6], "highest": 6, "highli": 6, "hit": 1, "hold": 2, "home": 2, "homework": 1, "hostedtoolcach": [4, 6], "how": [1, 2, 3, 4, 5, 6], "howev": [1, 2, 3, 5, 6], "html": [0, 4, 6], "http": [4, 6], "huge": 1, "huggingfac": 4, "huggingface_hub": 6, "huh": 4, "hundr": 1, "hyperparamet": 4, "hypothesi": 1, "hypothet": [5, 6], "i": [1, 2, 3, 4, 5, 6], "id": [1, 3, 4, 6], "idea": [2, 3, 5], "ident": 3, "identifi": 4, "idx": 4, "implement": [2, 3], "implicitli": 4, "import": [1, 2, 3, 4, 5, 6], "importantli": 2, "impos": 2, "impress": 3, "improv": [1, 2, 3], "in_featur": [3, 6], "includ": [4, 5], "incom": 5, "incorpor": 5, "increas": 2, "increasingli": 2, "incred": 2, "incredibli": 2, "inde": [2, 3, 6], "indic": 5, "indirect": 5, "individu": [2, 3, 4], "inf": [4, 5], "infer": 5, "influenc": 2, "inform": [2, 5], "initi": [1, 2, 4, 5], "inplac": [0, 6], "input": [1, 2, 3, 4, 5, 6], "input_id": [4, 6], "input_valu": 2, "inscrut": 5, "insid": 6, "insight": 1, "inspect": [4, 6], "instabl": 5, "instal": [0, 6], "instanc": 6, "instanti": 4, "instead": [1, 2, 3, 4, 5, 6], "instruct": [5, 6], "int": 4, "integ": 4, "intend": 2, "interact": [3, 4], "interc": 2, "interest": [1, 2, 5], "interestingli": [3, 4], "intermedi": 6, "intern": 4, "interpret": [2, 5], "intimid": 2, "introduc": [1, 2, 3, 5, 6], "introduct": 1, "intuit": [2, 5], "involv": [1, 2, 3], "io": [4, 6], "iprogress": [4, 6], "ipynb": 0, "ipywidget": [4, 6], "is_caus": [5, 6], "isinst": 6, "issu": 4, "item": [4, 5, 6], "iter": [1, 2, 4], "its": [1, 2, 3, 4, 5, 6], "itself": 5, "j": 5, "job": 4, "join": 4, "jupyt": [0, 4, 6], "just": [1, 2, 3, 4, 5, 6], "k": [2, 3, 5], "k_0": 5, "k_b": 5, "k_view": 5, "keep": [3, 4, 6], "keepdim": 3, "kei": [1, 4, 6], "kind": [2, 3, 4], "know": [1, 2, 3], "knowledg": [1, 2], "known": [1, 2, 3], "l": [2, 3, 4, 6], "label": 2, "lage": 2, "lambda": 4, "languag": [2, 4, 5, 6], "larg": [2, 4, 6], "larger": 4, "last": [1, 3, 6], "last_logit": 6, "later": [1, 2, 4, 6], "layer": [1, 2, 6, 7], "layer_block": 6, "layer_norm": 3, "layer_norm_torch": 3, "layernorm": [3, 6], "lazi": 3, "lead": [1, 2, 4, 6], "learn": [1, 2, 3, 4, 5], "learnabl": 3, "left": 4, "len": [4, 6], "length": [4, 6], "less": [1, 2], "let": [1, 2, 3, 4, 5, 6], "letter": 1, "level": [2, 3, 7], "lib": [4, 6], "like": [1, 2, 3, 4, 5, 6], "limit": 4, "line": [2, 3], "line2d": [2, 3], "linear": 6, "linguist": 5, "list": [1, 2, 4, 6], "llm": [1, 3, 4, 6], "lm_head": 6, "ln_1": 6, "ln_2": 6, "ln_f": 6, "load": 4, "local": [2, 6], "local_grad": 2, "locat": 3, "log": 2, "logic": 2, "long": [2, 3, 4, 6], "longer": 3, "look": [1, 2, 3, 4, 5, 6], "lookup": 3, "loop": 2, "lose": 3, "loss": [2, 6], "loss_fun": 2, "lost": 3, "lot": [1, 2, 4, 5, 6], "low": [1, 2], "lower": 2, "lr": 2, "luckili": [2, 3], "m": [2, 4], "machin": [2, 4, 6], "made": 5, "magnitud": 2, "mai": [2, 4], "mainli": 4, "make": [1, 2, 3, 4], "manag": 1, "mani": [1, 2, 4, 6], "manual": [2, 3, 4, 5, 6], "manual_i": 3, "manual_se": [3, 5, 6], "manual_y_0": 3, "manual_y_1": 3, "map": [2, 3, 4], "mask": [5, 6], "mask_b": 5, "masked_fil": 5, "maskedfillbackward0": 5, "match": [3, 5], "math": [2, 3], "mathbb": [2, 3], "mathbf": 5, "mathemat": [1, 2, 3, 5], "matmul": [2, 3, 5], "matplotlib": [2, 3], "matric": [2, 5], "matrix": [2, 3, 5], "matter": [2, 6], "max": [2, 3, 4], "maximum": [1, 2, 3], "mean": [1, 2, 3, 6], "meaning": [1, 2, 6], "meant": 2, "measur": 2, "mechan": [1, 2, 5, 6], "memor": 2, "memori": 6, "mention": [2, 3, 4], "merg": [4, 6], "meta": 1, "method": [3, 4], "might": [1, 2, 3, 4, 5, 6], "million": 1, "mimick": 6, "min": 4, "minim": 2, "minor": 5, "minut": 2, "miss": [2, 5], "mitig": 2, "mix": [1, 5], "mlp_input": 6, "mlp_output": 6, "mlp_residu": 6, "mode": 3, "model": [2, 3, 4, 5], "modeling_gpt2": 6, "modeling_output": 6, "modern": [1, 3, 4], "modul": [3, 5, 6], "modulelist": 6, "moment": 2, "monoton": 2, "more": [1, 2, 3, 4, 5, 6], "most": [0, 1, 2, 3, 4, 5, 6], "most_common_token_pair": 4, "mostli": [1, 2, 5], "motiv": 2, "move": [2, 4], "much": [1, 2, 3, 5], "mul": 2, "mulbackward": 2, "multidimension": 2, "multinomi": 6, "multipl": [1, 2, 3, 4, 5], "multipli": 2, "multitud": 2, "n": [2, 4], "n_head": 5, "n_token": 5, "name": [1, 2, 3, 5, 6], "named_paramet": 3, "nativelayernormbackward0": 3, "natur": [3, 4], "nbconvert": 0, "necessarili": 1, "need": [1, 2, 3, 4, 5, 6], "net": 2, "network": [3, 5, 6], "neural": [3, 5, 6], "neuralnetwork": 2, "neuron": 3, "never": [3, 4], "nevertheless": 2, "new": [2, 3, 4, 5], "new_shap": 6, "new_token_id": 4, "newfound": 1, "newgeluactiv": 6, "next": [1, 2, 3, 5, 6], "next_token": 6, "next_token_id": 6, "nice": [2, 5], "nlp": [2, 3], "nn": [2, 3, 5, 6], "no_grad": 2, "node": [2, 3], "non": 6, "none": 6, "nonlinear": 3, "nonzero": 3, "norm_x": 3, "normal": [5, 6], "normalized_attention_input": 6, "normalized_nlp_input": 6, "notat": 2, "note": [1, 2, 3, 5, 6], "notebook": 0, "notebook_tqdm": [4, 6], "noth": 2, "now": [1, 2, 3, 4, 5, 6], "np": [2, 3], "nthei": 4, "nthere": 4, "ntoken": 4, "num_embed": 3, "num_head": 6, "num_merg": 4, "num_sampl": 6, "num_token": 5, "number": [2, 3, 4, 5, 6], "numer": [2, 4, 5, 6], "numpi": [2, 3], "o": 6, "object": [2, 4, 6], "observ": [3, 4], "obtain": [2, 3, 5], "obvious": [1, 2], "occur": 2, "occurr": 4, "off": [3, 4], "often": [1, 2, 4, 5, 6], "ok": 1, "old_token_id": 4, "omit": 4, "onc": [4, 5], "one": [1, 2, 3, 5, 6], "ones": [3, 5], "onli": [1, 2, 3, 4, 5, 6], "open": 1, "openai": [1, 6], "oper": [2, 3, 4, 6], "opposit": 4, "opt": [4, 6], "optim": [1, 3], "order": [1, 2, 6], "origin": 4, "original_text": 4, "other": [1, 2, 3, 4, 5], "otherwis": [2, 3, 6], "otim": 2, "our": [1, 3, 4, 5, 6], "out": [1, 2, 3, 4, 5, 6], "out_featur": [3, 6], "outer": 2, "output": [1, 2, 3, 4, 5, 6], "output_nod": 2, "output_valu": 2, "outsid": 3, "over": [1, 2, 3, 4], "overal": 5, "overfit": [1, 3], "overview": [2, 7], "own": [4, 5], "p": [3, 4, 6], "p0": 4, "p1": 4, "packag": [2, 3, 4, 5, 6], "pai": [1, 4, 5], "pair": 5, "paragraph": 1, "parallel": 5, "param": 3, "paramet": [1, 3, 5, 6], "part": [1, 4, 5], "partial": [2, 3, 6], "particular": [2, 5, 6], "particularli": [1, 5], "pass": [2, 3, 6], "pattern": 2, "penalti": 2, "peopl": [2, 3], "per": 1, "perceptron": 2, "perform": [2, 3, 4, 5], "permut": 6, "perspect": 3, "pet": 1, "phi": 3, "piec": [1, 5], "pip": 0, "pipelin": 0, "pleas": [4, 6], "plot": [2, 3], "plt": [2, 3], "point": [1, 2, 3, 5], "pollut": 6, "popular": 4, "posit": [1, 3, 6], "position_emb": 6, "position_id": 6, "possibl": [1, 3, 4, 5], "postfix": 5, "potenti": 6, "practic": [1, 3, 5], "practicion": 2, "pratic": 2, "preced": 2, "predefin": 4, "predic": 5, "predict": [1, 2, 6], "predictor": 1, "present": [1, 3, 6], "pretti": [2, 4], "prevent": 2, "previou": [1, 2, 3], "primarili": 5, "print": [2, 3, 4, 5, 6], "prob": 6, "proba": 6, "probabl": [1, 2, 3, 5, 6], "probe": 5, "problem": [2, 3, 4, 5, 6], "process": [1, 2, 4, 5, 6], "produc": [1, 2, 3, 4, 5], "product": [2, 3, 5], "progress": [3, 5, 6], "project": 6, "projection_output": 6, "propag": [2, 6], "properti": 1, "proport": 2, "proportion": 2, "provid": [1, 2, 3, 6], "provis": 6, "pt": [4, 6], "public": 6, "pull": 2, "punctuat": 4, "purpos": [2, 4, 6], "put": [2, 3, 5], "py": [4, 6], "pyplot": [2, 3], "python": [2, 4, 6], "python3": [4, 6], "pytorch": [3, 5, 6], "q": [2, 5], "q_0": 5, "q_1": 2, "q_2": 2, "q_b": 5, "q_i": 2, "q_view": 5, "quantifi": 2, "quantum": 2, "queri": [1, 6], "query_key_valu": 6, "question": [2, 4, 5], "quick": [2, 6], "quickli": 2, "quit": [1, 2, 4], "r": [0, 2, 3, 4, 5], "r_b": 5, "r_combin": 5, "r_torch": 5, "randn": [3, 5], "random": [1, 3, 5, 6], "randomli": [1, 2, 3], "rang": [2, 3, 4, 5], "rather": 2, "raw": 4, "re": 2, "reach": 1, "read": 6, "readthedoc": [4, 6], "real": 5, "realiti": [1, 2, 5], "realiz": 5, "realli": [1, 2, 3], "reason": [2, 4, 5, 6], "recal": 2, "recalcul": 2, "receiv": 3, "recent": 1, "recomput": 3, "rectifi": 3, "recurs": 4, "redo": [3, 6], "redpajama": 1, "reduc": 5, "refer": 6, "regard": 2, "register_buff": 5, "reiter": 2, "rel": [1, 3], "releas": 6, "relev": [1, 2, 4, 5, 6], "relu": 3, "relu_i": 3, "relu_x": 3, "rememb": [1, 2, 5, 6], "remind": 6, "renam": 6, "repeatedli": [1, 2, 4], "repetit": [1, 6], "replac": 4, "repositori": 0, "repr": 4, "repres": [1, 2, 3, 4, 5, 6], "represent": [1, 2, 5, 6], "reproduc": [2, 3, 6], "requir": [0, 1], "requires_grad": [2, 3], "reshap": 5, "resid_dropout": 6, "residu": 6, "resourc": 1, "respect": [2, 3, 4, 5, 6], "respond": 1, "respons": [1, 6], "respres": 2, "rest": [2, 4], "restrict": 2, "result": [1, 2, 3, 4, 5, 6], "retain_grad": 2, "retriev": [3, 5, 6], "return": [2, 3, 4, 5, 6], "return_tensor": [4, 6], "reus": 6, "reveal": 3, "rich": 3, "richer": 5, "right": [2, 5], "rightarrow": 2, "robust": 3, "role": 4, "root": [0, 3], "round": [5, 6], "row": [3, 5], "rule": 2, "run": [0, 1, 2], "s_b": 5, "s_mask": 5, "s_masked_b": 5, "s_masked_sc": 5, "s_masked_scaled_b": 5, "s_scale": 5, "sai": [1, 2, 3, 5], "same": [1, 2, 3, 4, 5, 6], "sampl": [1, 3, 6], "sampled_token_id": 6, "saniti": 2, "save": 6, "saw": 2, "scale": [3, 5], "scaled_dot_product_attent": [5, 6], "scari": 2, "scheme": 2, "school": 2, "sci_mod": 3, "scientif": 3, "score": [1, 5, 6], "scratch": [2, 3], "sdpa_output": 6, "sdpa_output_transpos": 6, "sdpa_output_view": 6, "search": 5, "second": [1, 2, 3, 4, 6], "section": [1, 2, 5], "see": [2, 3, 4, 5, 6], "seed": [3, 6], "seem": [1, 4, 5], "seen": 6, "select": [1, 6], "self": [2, 3, 5], "semant": [1, 3], "sens": [2, 4, 5], "sensibl": 5, "sentenc": [1, 3, 4, 5, 6], "separ": [3, 4, 6], "seqquenc": 4, "sequenc": [1, 4, 5, 6], "sequenti": 5, "serv": 1, "set": [2, 3, 4, 5, 6], "set_printopt": 3, "settl": 4, "setup": 2, "seven": 1, "sgd": 2, "shame": 3, "shamelessli": 2, "shape": [3, 5, 6], "shenanigan": 4, "shift": 3, "short": 3, "should": [1, 2, 4, 5, 6], "show": 4, "showcas": 2, "side": 3, "sigma": 2, "sigmoid": [2, 3], "sigmoid_derivative_i": 3, "sigmoid_derivative_x": 3, "sigmoid_i": 2, "sigmoid_x": 2, "sigmoidbackward": 2, "sigmoidbackward0": 2, "signal": [3, 6], "similar": [1, 2, 3, 5, 6], "similarli": [2, 4, 5], "simpl": [1, 2, 3, 4, 5, 6], "simplenet": 2, "simplest": [2, 3, 4, 5, 6], "simpli": [2, 3, 4, 6], "simplifi": [2, 3], "sinc": [1, 2, 4, 5, 6], "singl": [3, 4, 5, 6], "site": [4, 6], "situat": 5, "size": [2, 3, 4, 5, 6], "sketch": 1, "slicebackward0": 6, "slightli": 2, "slowli": 2, "small": [2, 3, 4, 6], "smaller": [2, 4], "smirk": 2, "so": [1, 2, 3, 4, 6], "softmax": [5, 6], "softmaxbackward0": [5, 6], "solv": [2, 3], "some": [1, 2, 3, 4, 5, 6], "somehow": 2, "someth": [1, 2, 3, 4], "sometim": 2, "somewher": 4, "sophist": 1, "sort_backward": 2, "sort_forward": 2, "sound": [2, 3], "sourc": 3, "space": 1, "spatial": 3, "speak": [2, 3, 6], "special": [1, 4], "specif": [3, 4, 6], "specifi": 2, "speed": 3, "spend": 1, "split": [1, 2, 4, 6], "sqrt": [3, 5], "squash": 2, "stab": 5, "stabil": 3, "stabl": [4, 6], "stack": [2, 3, 5], "stackbackward0": 3, "stand": 1, "standalon": 1, "start": [2, 4, 5, 6], "state": [2, 6], "staticmethod": 2, "step": [2, 4, 6], "stick": [2, 6], "still": [2, 3, 5], "stole": 2, "stop": 1, "store": [2, 6], "straighforward": 2, "strang": 4, "strategi": [2, 4], "stress": 2, "string": 4, "structur": 2, "subgradi": 2, "subgraph": 3, "subject": 5, "subtract": 2, "successfulli": [2, 5], "sum": [1, 5], "summari": 3, "super": [3, 5], "sure": 3, "surprisingli": 5, "surround": 5, "t": [1, 2, 3, 4, 5, 6], "t1": 2, "t2": 2, "t_0": 5, "t_1": 5, "t_2": 5, "t_grad_loc": 2, "tabl": [2, 3, 7], "take": [1, 2, 3, 5, 6], "taken": 6, "talk": [1, 2, 3], "target": 2, "task": 2, "teach": 2, "team": 2, "technic": [1, 2, 3, 4, 5], "techniqu": [2, 3], "tediou": [2, 4], "tell": 2, "ten": [1, 4], "tend": 1, "tensor": [3, 4, 5, 6], "tensor0": 2, "tensor1": 2, "tensor2": 2, "tensor3": 2, "tensordot": 2, "term": 6, "terminologi": 6, "terribli": 2, "test": [2, 5], "text": [1, 2, 4, 6], "th": 1, "than": [1, 2, 4, 5, 6], "thei": [1, 2, 3, 4, 5], "them": [0, 1, 2, 3, 4, 5, 6], "themselv": 4, "theoret": [2, 4, 5], "theori": [2, 4], "therefor": [1, 2, 3, 4, 5, 6], "thi": [0, 1, 2, 3, 4, 5, 6], "thing": [1, 2, 5, 6], "think": [2, 3, 5], "third": [1, 2, 3, 6], "those": [1, 2], "though": [1, 3, 6], "thousand": 1, "three": [2, 5, 6], "through": [2, 3, 5, 6], "throughout": [4, 5], "thu": [2, 5], "tiktoken": 4, "time": [1, 2, 3, 4, 5, 6], "ting": 1, "togeth": [1, 2, 5, 6], "toi": 2, "token": [1, 5, 6, 7], "token_emb": 6, "token_id": [4, 6], "token_pair_count": 4, "tokenization_gpt2_fast": [4, 6], "tokenization_utils_bas": 4, "tokenize_charact": 4, "tokenize_word": 4, "too": [0, 2, 3, 4, 6], "tool": 4, "top": [2, 3, 5, 6], "top_k": 6, "top_k_id": 6, "top_k_prob": 6, "top_k_token": 6, "topic": 1, "topk": 6, "torch": [2, 3, 5, 6], "torchsimplenet": 2, "torchsimplenetv2": 2, "total": 2, "tqdm": [4, 6], "tqdmwarn": [4, 6], "tradition": 1, "train": [2, 3, 4, 5], "transform": [1, 6], "translat": 4, "transpos": [2, 5, 6], "treat": [2, 3, 4], "tremend": 2, "tri": 2, "tril": 5, "trillion": 1, "trivial": [2, 3], "true": [1, 2, 3, 4, 5, 6], "truli": 6, "truth": [2, 3], "try": [2, 3, 5], "turn": [2, 5], "two": [1, 2, 3, 4, 6], "txt": 0, "type": [1, 4, 6], "u": [2, 3, 4, 5, 6], "unbias": 3, "unchang": 6, "underli": [1, 2], "underpin": 2, "understand": [1, 2, 3, 4, 5, 6], "understood": 2, "undesir": 1, "unfortun": [3, 5], "unit": [3, 4], "unless": 3, "unnecessari": 2, "unsafeviewbackward0": [5, 6], "unseen": 2, "unstabl": 2, "until": 1, "unusu": 2, "up": [1, 2, 3, 4, 5, 6], "updat": [3, 4, 6], "upon": 1, "us": [0, 1, 2, 3, 4, 5, 6], "usabl": 4, "usag": 3, "user": 1, "user_instal": [4, 6], "usual": [1, 2, 3, 4, 5, 6], "utf": 4, "util": 1, "v": [2, 3, 5], "v2": 1, "v4": 4, "v_b": 5, "v_view": 5, "valid": 2, "valu": [1, 2, 3, 6], "vanish": 6, "vanishingli": 6, "var": 3, "variabl": [5, 6], "varianc": 3, "variant": 3, "variou": 2, "ve": [2, 4], "vec": [2, 3], "vector": [1, 2, 3], "vehicl": 1, "veri": [1, 2, 3, 4, 5, 6], "verifi": [2, 3, 5, 6], "version": [2, 6], "via": [3, 5], "view": [3, 4, 5, 6], "viewbackward0": 3, "visual": [1, 2, 6], "vocab": 4, "vocab_s": 4, "vocabulari": [4, 6], "vw": 3, "w": [2, 3, 5], "w1": 2, "w2": 2, "w_": 5, "w_0": 5, "w_1": [2, 5], "w_2": [2, 5], "w_b": 5, "w_k": 5, "w_k_b": 5, "w_mask": 5, "w_q": 5, "w_q_b": 5, "w_v": 5, "w_v_b": 5, "wa": [1, 3, 4, 6], "wai": [2, 3, 4, 5, 6], "want": [1, 2, 3, 4, 5, 6], "warn": 4, "watch": 3, "wavi": 5, "we": [1, 2, 3, 4, 5, 6], "weight": [2, 3, 5, 6], "well": [1, 2, 3, 4, 5, 6], "were": [4, 5], "what": [1, 2, 3, 4, 5, 6], "when": [1, 2, 3, 4, 5, 6], "whenev": [3, 6], "where": [2, 3, 4, 5, 6], "which": [1, 2, 3, 4, 5, 6], "while": [1, 2, 4, 5], "whitespac": 4, "who": 1, "why": [1, 2, 3, 6], "widespread": 6, "wise": 2, "without": [2, 5, 6], "wizardri": 2, "won": [3, 6], "word": [1, 2, 3, 4], "work": [1, 2, 3, 5, 6], "world": 4, "worri": 2, "would": [0, 1, 2, 3, 4, 5, 6], "wouldn": 2, "wpe": 6, "write": [2, 4], "written": [2, 6], "wte": 6, "wx": 5, "x": [2, 3, 4, 5, 6], "x1": 2, "x2": 2, "x64": [4, 6], "x_0": 5, "x_1": [2, 5], "x_2": [2, 5], "x_b": 5, "x_i": 5, "x_j": 5, "x_norm": 3, "y": [2, 3, 5, 6], "y_0": 5, "y_1": 5, "y_2": 5, "y_grad_loc": 2, "y_i": 5, "ye": 2, "yet": 5, "yield": [2, 5], "you": [1, 2, 3, 4, 5, 6], "your": [2, 3, 5, 6], "z": [2, 3], "zero": [2, 3], "zero_": 2, "zero_grad": 2, "zip": [4, 6], "\u0121": 4, "\u0121a": 4, "\u0121i": 4, "\u0121sentenc": 4}, "titles": ["Large Language Models book", "High-Level Overview", "Computational Graphs and Backpropagation", "Basic Layers", "Tokenization", "Attention", "Deep Dive Into GPT-2", "Preface"], "titleterms": {"": 1, "2": 6, "Into": 6, "It": 1, "The": [1, 2, 3, 4, 5, 6], "activ": 3, "algorithm": [2, 4], "all": 1, "architectur": 6, "attent": [5, 6], "backpropag": 2, "basic": 3, "batch": 5, "block": 6, "book": 0, "build": 0, "byte": 4, "calcul": 6, "combin": 5, "compon": 1, "comput": 2, "contribut": 0, "deep": 6, "dimens": 5, "dive": 6, "down": 1, "dropout": 3, "embed": [3, 6], "encod": 4, "execut": 1, "explod": 2, "final": 4, "first": [2, 6], "four": 1, "function": 3, "gpt": 6, "gpt2": 6, "gradient": 2, "graph": 2, "head": 5, "high": 1, "idea": 4, "implement": 5, "infer": 6, "kei": 5, "languag": [0, 1], "larg": [0, 1], "layer": [3, 5], "level": 1, "librari": 4, "linear": [3, 5], "load": 6, "logit": 6, "mlp": 6, "model": [0, 1, 6], "multi": 5, "naiv": 5, "network": 2, "neural": 2, "normal": 3, "note": 4, "number": 1, "optim": 2, "other": 6, "our": 2, "overfit": 2, "overview": 1, "pair": 4, "paramet": 2, "part": 6, "perform": 6, "prefac": 7, "pytorch": 2, "queri": 5, "regular": 2, "selfattent": 5, "subword": 4, "summari": 1, "tensor": 2, "token": 4, "train": 1, "transform": 4, "updat": 2, "valu": 5, "vanish": 2, "vector": 5, "wai": 1}})